{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/willcosta29/Pipeline_telegram_bot/blob/main/Pipeline_telegram_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJqp9AANOCtf"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/andre-marcos-perez/ebac-course-utils/main/media/logo/newebac_logo_black_half.png\" alt=\"ebac-logo\">\n",
        "\n",
        "---\n",
        "\n",
        "# **Módulo** | Pipeline de Dados do Telegram I\n",
        "Caderno de **Exercícios**<br>\n",
        "Professor [André Perez](https://www.linkedin.com/in/andremarcosperez/)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmoHgt-lwkpD"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01e4d056"
      },
      "source": [
        "O código abaixo importa a função `getpass` para solicitar de forma segura o token do bot do Telegram."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "token = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1ekiRdzb_Zf",
        "outputId": "1668fab8-8c33-4363-b7fe-3bdc7a0088db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08922e9e"
      },
      "source": [
        "Este trecho de código importa as bibliotecas `json` e `requests` e constrói a URL base para a API do Bot do Telegram usando o token fornecido."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "import requests\n",
        "\n",
        "base_url = f'https://api.telegram.org/bot{token}'"
      ],
      "metadata": {
        "id": "Xy7K9wAvcC09"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b33e868c"
      },
      "source": [
        "Este código faz uma chamada à API `getMe` para verificar as informações do bot e imprime a resposta."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(url=f'{base_url}/getMe')\n",
        "print(f'{base_url}/getMe')\n",
        "\n",
        "print(json.dumps(json.loads(response.text), indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PK6XLYNcF41",
        "outputId": "35210fc7-90b2-4b76-f978-20fb66bb19cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://api.telegram.org/bot8392968942:AAEx1JbGBP2byiJw2FPcRYL5nwGxV7auJBI/getMe\n",
            "{\n",
            "  \"ok\": true,\n",
            "  \"result\": {\n",
            "    \"id\": 8392968942,\n",
            "    \"is_bot\": true,\n",
            "    \"first_name\": \"chubby_data_ebac_test\",\n",
            "    \"username\": \"will_ebac_bot\",\n",
            "    \"can_join_groups\": false,\n",
            "    \"can_read_all_group_messages\": false,\n",
            "    \"supports_inline_queries\": false,\n",
            "    \"can_connect_to_business\": false,\n",
            "    \"has_main_web_app\": false\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9c2afd4"
      },
      "source": [
        "Este código faz uma chamada à API `getUpdates` para buscar por novas mensagens e imprime a resposta. Note que pode ocorrer um erro se um webhook estiver ativo."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(url=f'{base_url}/getUpdates')\n",
        "\n",
        "print(json.dumps(json.loads(response.text), indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHCngIrvcIue",
        "outputId": "18d89497-4d93-43a6-beba-ab98850dd87b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"ok\": false,\n",
            "  \"error_code\": 409,\n",
            "  \"description\": \"Conflict: can't use getUpdates method while webhook is active; use deleteWebhook to delete the webhook first\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('telegram.json', mode='w', encoding='utf8') as fp:\n",
        "  json.dump(json.loads(response.text), fp, indent=2)"
      ],
      "metadata": {
        "id": "L8aTxt43iiOo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85fdaf0a"
      },
      "source": [
        "Este código salva a resposta da API `getUpdates` em um arquivo JSON chamado `telegram.json`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('telegram.json', mode='r', encoding='utf8') as fp:\n",
        "  data = json.load(fp)\n",
        "  for update in data.get(\"result\", []):\n",
        "    if \"message\" in update:\n",
        "      message = update[\"message\"]\n",
        "      print(message)"
      ],
      "metadata": {
        "id": "aRGrtNwWiIuV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de6708c2"
      },
      "source": [
        "Este código lê o arquivo `telegram.json` e itera sobre a lista de atualizações ('result'), imprimindo as mensagens encontradas."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(json.dumps(data, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK1DJNmOjNr_",
        "outputId": "962fec8e-fc2e-4769-ada8-e93503e03185"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"ok\": false,\n",
            "  \"error_code\": 409,\n",
            "  \"description\": \"Conflict: can't use getUpdates method while webhook is active; use deleteWebhook to delete the webhook first\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "date = datetime.now().strftime('%Y-%m-%d')\n",
        "timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "parsed_data = dict()\n",
        "\n",
        "for key, value in data.items():\n",
        "\n",
        "    if key == 'from':\n",
        "        for k, v in data[key].items():\n",
        "            if k in ['id', 'is_bot', 'first_name']:\n",
        "              parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n",
        "\n",
        "    elif key == 'chat':\n",
        "        for k, v in data[key].items():\n",
        "            if k in ['id', 'type']:\n",
        "              parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n",
        "\n",
        "    elif key in ['message_id', 'date', 'text']:\n",
        "        parsed_data[key] = [value]\n",
        "\n",
        "if not 'text' in parsed_data.keys():\n",
        "  parsed_data['text'] = [None]\n",
        "\n",
        "parsed_data['context_date'] = [date]\n",
        "parsed_data['context_timestamp'] = [timestamp]"
      ],
      "metadata": {
        "id": "COdXAhBNjSfg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in parsed_data.items():\n",
        "  print(f\"{k}: {v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZLO7sNMjayN",
        "outputId": "7d5c1fef-ba3d-40b8-e408-54d7832d542e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text: [None]\n",
            "context_date: ['2025-10-29']\n",
            "context_timestamp: ['2025-10-29 20:37:28']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyarrow as pa\n",
        "\n",
        "table = pa.Table.from_pydict(mapping=parsed_data)"
      ],
      "metadata": {
        "id": "H_vKEX15jcK1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZdmgaFgjjid",
        "outputId": "225ba8f3-1dee-49b8-88a4-e361b078f824"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyarrow.Table\n",
              "text: null\n",
              "context_date: string\n",
              "context_timestamp: string\n",
              "----\n",
              "text: [1 nulls]\n",
              "context_date: [[\"2025-10-29\"]]\n",
              "context_timestamp: [[\"2025-10-29 20:37:28\"]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTUzybLXsU52",
        "outputId": "85a0b031-f996-4053-8d26-a92acfd2d3b1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.40.61-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting botocore<1.41.0,>=1.40.61 (from boto3)\n",
            "  Downloading botocore-1.40.61-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3)\n",
            "  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.61->boto3) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.61->boto3) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.61->boto3) (1.17.0)\n",
            "Downloading boto3-1.40.61-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.40.61-py3-none-any.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.40.61 botocore-1.40.61 jmespath-1.0.1 s3transfer-0.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "import boto3\n",
        "\n",
        "\n",
        "def lambda_handler(event: dict, context: dict) -> dict:\n",
        "\n",
        "  '''\n",
        "  Recebe uma mensagens do Telegram via AWS API Gateway, verifica no\n",
        "  seu conteúdo se foi produzida em um determinado grupo e a escreve,\n",
        "  em seu formato original JSON, em um bucket do AWS S3.\n",
        "  '''\n",
        "\n",
        "  # vars de ambiente\n",
        "\n",
        "  BUCKET = os.environ['AWS_S3_BUCKET']\n",
        "  TELEGRAM_CHAT_ID = int(os.environ['TELEGRAM_CHAT_ID'])\n",
        "\n",
        "  # vars lógicas\n",
        "\n",
        "  tzinfo = timezone(offset=timedelta(hours=-3))\n",
        "  date = datetime.now(tzinfo).strftime('%Y-%m-%d')\n",
        "  timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')\n",
        "\n",
        "  filename = f'{timestamp}.json'\n",
        "\n",
        "  # código principal\n",
        "\n",
        "  client = boto3.client('s3')\n",
        "\n",
        "  try:\n",
        "\n",
        "    message = json.loads(event[\"body\"])\n",
        "    chat_id = message[\"message\"][\"chat\"][\"id\"]\n",
        "\n",
        "    if chat_id == TELEGRAM_CHAT_ID:\n",
        "\n",
        "      with open(f\"/tmp/{filename}\", mode='w', encoding='utf8') as fp:\n",
        "        json.dump(message, fp)\n",
        "\n",
        "      client.upload_file(f'/tmp/{filename}', BUCKET, f'telegram/context_date={date}/{filename}')\n",
        "\n",
        "  except Exception as exc:\n",
        "      logging.error(msg=exc)\n",
        "      return dict(statusCode=\"500\")\n",
        "\n",
        "  else:\n",
        "      return dict(statusCode=\"200\")"
      ],
      "metadata": {
        "id": "8hDrA0xnrxrx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "from datetime import datetime, timedelta, timezone\n",
        "\n",
        "import boto3\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "# Configuração de logging no nível superior para melhor visibilidade no CloudWatch\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "\n",
        "def parse_data(data: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Processa e achata (flatten) a estrutura aninhada da mensagem do Telegram\n",
        "    para um formato adequado ao PyArrow/Parquet, garantindo a coerência de tipos.\n",
        "    \"\"\"\n",
        "    parsed_data = dict()\n",
        "\n",
        "    # Mapeamento e Coerção de Tipos\n",
        "    for key, value in data.items():\n",
        "        if key == 'from':\n",
        "            for k, v in data[key].items():\n",
        "                # Coleta 'id', 'is_bot', 'first_name' do remetente\n",
        "                if k in ['id', 'is_bot', 'first_name']:\n",
        "                    # Renomeia para evitar conflito e esclarecer\n",
        "                    parsed_data[f\"user_{k}\"] = [v]\n",
        "\n",
        "        elif key == 'chat':\n",
        "            for k, v in data[key].items():\n",
        "                # Coleta 'id', 'type' do chat\n",
        "                if k in ['id', 'type']:\n",
        "                    # Renomeia para evitar conflito e esclarecer\n",
        "                    parsed_data[f\"chat_{k}\"] = [v]\n",
        "\n",
        "        elif key in ['message_id', 'date', 'text']:\n",
        "            parsed_data[key] = [value]\n",
        "\n",
        "    # 1. Lista de campos que devem ser inteiros e strings\n",
        "    INT_FIELDS = ['message_id', 'date', 'user_id', 'chat_id']\n",
        "    BOOL_FIELDS = ['user_is_bot']\n",
        "\n",
        "    for key, values in parsed_data.items():\n",
        "        if not values or values[0] is None:\n",
        "            continue\n",
        "\n",
        "        value = values[0]\n",
        "\n",
        "        # Coerção para Inteiro (para IDs e Date/Timestamp)\n",
        "        if key in INT_FIELDS:\n",
        "            try:\n",
        "                parsed_data[key] = [int(value)]\n",
        "            except (ValueError, TypeError):\n",
        "                # Se a conversão falhar (ex: string não numérica), trata como NULL\n",
        "                parsed_data[key] = [None]\n",
        "                logger.warning(f\"Coerção de tipo falhou para {key} com valor '{value}'. Definido como None.\")\n",
        "\n",
        "        elif key in BOOL_FIELDS:\n",
        "            if isinstance(value, str):\n",
        "                 v = value.lower() == 'true'\n",
        "            else:\n",
        "                 v = bool(value)\n",
        "            parsed_data[key] = [v]\n",
        "\n",
        "        # Coerção para String (para 'text', 'first_name', 'chat_type')\n",
        "        elif not isinstance(value, str):\n",
        "            parsed_data[key] = [str(value)]\n",
        "\n",
        "    # --- FIM DA CORREÇÃO DE SCHEMA ---\n",
        "\n",
        "    # Garante que a coluna 'text' sempre exista (para manter o schema)\n",
        "    if 'text' not in parsed_data.keys():\n",
        "        parsed_data['text'] = [None]\n",
        "\n",
        "    return parsed_data\n",
        "\n",
        "\n",
        "def lambda_handler(event: dict, context: dict) -> bool:\n",
        "    '''\n",
        "    Diariamente é executado para compactar as diversas mensagens no formato\n",
        "    JSON do dia anterior, armazenadas no bucket de dados cru, em um único\n",
        "    arquivo PARQUET, armazenando-o no bucket de dados enriquecidos.\n",
        "    '''\n",
        "\n",
        "    logger.info(\"Iniciando a execução da função Lambda para compactação.\")\n",
        "\n",
        "    # 1. Variáveis de Ambiente e Lógicas\n",
        "    try:\n",
        "        RAW_BUCKET = os.environ['AWS_S3_BUCKET']\n",
        "        ENRICHED_BUCKET = os.environ['AWS_S3_ENRICHED']\n",
        "    except KeyError as e:\n",
        "        logger.error(f\"Variável de ambiente obrigatória não definida: {e}\")\n",
        "        return False\n",
        "\n",
        "    # Define o fuso horário (UTC-3)\n",
        "    TZ_INFO = timezone(offset=timedelta(hours=-3))\n",
        "\n",
        "    # LÓGICA DE DATA - Alterado para Opção 2 de teste (melhor prática)\n",
        "    # Tenta usar 'date_override' do evento de teste; caso contrário, usa o dia anterior\n",
        "    date_to_process_str = event.get('date_override')\n",
        "\n",
        "    if date_to_process_str:\n",
        "        # Usando a data fornecida no JSON de teste\n",
        "        date_to_process = date_to_process_str\n",
        "        logger.warning(f\"Usando data forçada do evento: {date_to_process}\")\n",
        "    else:\n",
        "        # Lógica de produção: dia anterior\n",
        "        date_to_process = (datetime.now(TZ_INFO) - timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "        logger.info(f\"Usando data padrão do dia anterior: {date_to_process}\")\n",
        "\n",
        "    timestamp = datetime.now(TZ_INFO).strftime('%Y%m%d%H%M%S%f')\n",
        "    s3_prefix = f'telegram/context_date={date_to_process}'\n",
        "\n",
        "\n",
        "    # 2. DEFINIÇÃO EXPLÍCITA DO SCHEMA (Para garantir consistência)\n",
        "    # Define o esquema para prevenir o erro \"Schema at index 1 was different\"\n",
        "    output_schema = pa.schema([\n",
        "        pa.field('message_id', pa.int64()),\n",
        "        pa.field('date', pa.int64()), # Unix timestamp\n",
        "        pa.field('text', pa.string()),\n",
        "        pa.field('user_id', pa.int64()),\n",
        "        pa.field('user_is_bot', pa.bool_()),\n",
        "        pa.field('user_first_name', pa.string()),\n",
        "        pa.field('chat_id', pa.int64()),\n",
        "        pa.field('chat_type', pa.string())\n",
        "    ])\n",
        "\n",
        "    # 3. Código Principal\n",
        "    table = None\n",
        "    client = boto3.client('s3')\n",
        "    temp_file_list = []\n",
        "\n",
        "    try:\n",
        "        logger.info(f\"Buscando objetos no bucket '{RAW_BUCKET}' com prefixo: {s3_prefix}\")\n",
        "\n",
        "        response = client.list_objects_v2(Bucket=RAW_BUCKET, Prefix=s3_prefix)\n",
        "\n",
        "        if 'Contents' not in response:\n",
        "            logger.warning(f\"Nenhum arquivo encontrado para o prefixo: {s3_prefix}\")\n",
        "            return True\n",
        "\n",
        "        for content in response['Contents']:\n",
        "            key = content['Key']\n",
        "            local_filename = f\"/tmp/{key.split('/')[-1]}\"\n",
        "            temp_file_list.append(local_filename)\n",
        "\n",
        "            logger.info(f\"Baixando {key} para {local_filename}\")\n",
        "            client.download_file(RAW_BUCKET, key, local_filename)\n",
        "\n",
        "            # 3b. Leitura, Parseamento e Concatenação\n",
        "            with open(local_filename, mode='r', encoding='utf8') as fp:\n",
        "                data = json.load(fp)\n",
        "\n",
        "            if \"message\" in data:\n",
        "                parsed_data = parse_data(data=data[\"message\"])\n",
        "\n",
        "                # Usa o schema explícito para criar a tabela\n",
        "                iter_table = pa.Table.from_pydict(mapping=parsed_data, schema=output_schema)\n",
        "\n",
        "                if table is None:\n",
        "                    table = iter_table\n",
        "                else:\n",
        "                    table = pa.concat_tables([table, iter_table])\n",
        "            else:\n",
        "                logger.warning(f\"Arquivo {key} não contém a chave 'message'. Pulando.\")\n",
        "\n",
        "\n",
        "        # 3c. Escrita e Upload do Parquet\n",
        "        if table is not None:\n",
        "            output_key = f\"{s3_prefix}/{timestamp}.parquet\"\n",
        "            local_parquet_path = f'/tmp/{timestamp}.parquet'\n",
        "\n",
        "            logger.info(f\"Escrevendo tabela Parquet no caminho: {local_parquet_path}\")\n",
        "            pq.write_table(table=table, where=local_parquet_path)\n",
        "\n",
        "            logger.info(f\"Iniciando upload para o bucket '{ENRICHED_BUCKET}' como {output_key}\")\n",
        "            client.upload_file(local_parquet_path, ENRICHED_BUCKET, output_key)\n",
        "\n",
        "            logger.info(\"Upload concluído com sucesso!\")\n",
        "            return True\n",
        "        else:\n",
        "            logger.warning(\"Nenhuma tabela de dados válida foi gerada ou concatenada.\")\n",
        "            return True\n",
        "\n",
        "    except Exception as exc:\n",
        "        logger.error(f\"Erro Crítico durante o processamento: {exc}\", exc_info=True)\n",
        "        return False\n",
        "    finally:\n",
        "        # 4. Limpeza\n",
        "        for filepath in temp_file_list:\n",
        "            if os.path.exists(filepath):\n",
        "                os.remove(filepath)\n",
        "\n",
        "        parquet_file = f'/tmp/{timestamp}.parquet'\n",
        "        if os.path.exists(parquet_file):\n",
        "            os.remove(parquet_file)\n",
        "\n",
        "        logger.info(\"Limpeza de arquivos temporários concluída.\")"
      ],
      "metadata": {
        "id": "P52N5NdRqiG9"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}