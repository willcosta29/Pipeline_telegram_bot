# ü§ñ Pipeline de Dados do Telegram com AWS

## ‚ú® Vis√£o Geral do Projeto

Em um mundo digital dominado pela comunica√ß√£o instant√¢nea, os chatbots em plataformas como o Telegram tornaram-se ferramentas poderosas para intera√ß√£o automatizada e coleta de dados. Este projeto implementa um pipeline robusto e escal√°vel na AWS (Amazon Web Services) para transformar a comunica√ß√£o transacional de um grupo do Telegram em dados anal√≠ticos valiosos.

A motiva√ß√£o principal reside na diferen√ßa entre **Dados Transacionais** e **Dados Anal√≠ticos**:

| Tipo de Dado | Caracter√≠stica Principal | Exemplo no Projeto |
| :--- | :--- | :--- |
| **Transacional (Raw)** | Operacional, alta granularidade, foco na escrita r√°pida e integridade imediata. | Cada mensagem enviada no Telegram (Payload JSON). |
| **Anal√≠tico (Enriched)** | Hist√≥rico, sumarizado, estruturado (Parquet), foco na leitura otimizada e efici√™ncia de consulta. | Volume de mensagens por hora, m√©dia de caracteres por usu√°rio. |

O pipeline atua como uma ponte, movendo e transformando os dados brutos do Telegram para um formato anal√≠tico otimizado (Parquet particionado) na AWS, viabilizando an√°lises profundas de comportamento e engajamento do grupo.

## üöÄ Arquitetura do Pipeline

A arquitetura do projeto √© dividida em dois grandes sistemas: o **Sistema Transacional** (Telegram), respons√°vel pela gera√ß√£o de dados, e o **Sistema Anal√≠tico** (AWS), respons√°vel pelo processamento, armazenamento e consulta.

*(Diagrama de Arquitetura Conceitual)*

### 1. üí¨ Sistema Transacional (Telegram)

O Telegram, atrav√©s da sua Bot API e do mecanismo de Webhook, atua como a fonte de dados. Cada mensagem enviada em um grupo monitorado √© um evento que dispara o processo de ingest√£o.

#### Configura√ß√£o do Bot

| Etapa | Descri√ß√£o |
| :--- | :--- |
| **Cria√ß√£o do Bot** | O bot `will_ebac_bot` foi criado e configurado via `@BotFather`, obtendo o token necess√°rio. |
| **Defini√ß√£o de ADM** | O bot foi promovido a Administrador do grupo para garantir que possa receber e processar todas as mensagens. |
| **Configura√ß√£o de Privacidade** | A op√ß√£o para adicionar o bot a novos grupos foi desabilitada, focando sua opera√ß√£o apenas no grupo de destino. |

### 2. ‚òÅÔ∏è Sistema Anal√≠tico (AWS)

O sistema anal√≠tico √© a parte mais robusta do pipeline, composto pelas etapas de Ingest√£o (Raw), ETL (Enriched) e Apresenta√ß√£o (An√°lise).

#### 2.1. Ingest√£o (Raw Data - Near Real-Time)

Esta etapa recebe o payload JSON do Telegram e o armazena imediatamente no formato original, no S3. A comunica√ß√£o √© feita via Webhook integrado ao API Gateway.

| Componente | Configura√ß√£o / A√ß√£o |
| :--- | :--- |
| **Bucket S3** | Cria√ß√£o do bucket `project-pipeline-ebac-raw` para armazenamento dos dados brutos (JSON). |
| **Fun√ß√£o Lambda (Raw)** | Fun√ß√£o `project-pipeline-ebac-raw` em Python. Utiliza `boto3` para escrever o JSON do evento diretamente no S3, particionando por data (`context_date=YYYY-MM-DD`). |
| **API Gateway** | Cria√ß√£o de um m√©todo `POST` na API Gateway, servindo como endpoint HTTP para o Webhook do Telegram e integrado √† Fun√ß√£o Lambda Raw. |
| **IAM** | Anexa√ß√£o da pol√≠tica `AmazonS3FullAccess` ao role IAM para permitir a escrita no S3. |

#### 2.2. ETL (Enriched Data - Batch Di√°rio)

Esta etapa de Transforma√ß√£o (T) e Carregamento (L) √© agendada para rodar uma vez ao dia. Ela l√™ os m√∫ltiplos arquivos JSON brutos do dia anterior, aplica transforma√ß√µes de limpeza/estrutura√ß√£o, e salva o resultado no formato otimizado para an√°lise.

| Componente | Configura√ß√£o / A√ß√£o |
| :--- | :--- |
| **Fun√ß√£o Lambda (Enriched)**| O c√≥digo Python implementa a fun√ß√£o `parse_data` (achatar e tipar o JSON) e `lambda_handler` (consolidar JSONs em um √∫nico Parquet). |
| **Layer PyArrow** | Cria√ß√£o de uma Layer Lambda com a biblioteca `pyarrow` para habilitar a manipula√ß√£o e escrita do formato Parquet dentro do ambiente Lambda. |
| **Formato de Sa√≠da** | Os dados s√£o consolidados em um √∫nico arquivo Parquet, particionado por data (`context_date`), e armazenado no bucket `project-pipeline-ebac-enriched`. |
| **EventBridge (Scheduler)**| Cria√ß√£o de uma regra de agendamento (cron) para invocar a fun√ß√£o Lambda ETL diariamente, garantindo a execu√ß√£o do processo de compacta√ß√£o. |

#### 2.3. Apresenta√ß√£o (An√°lise Explorat√≥ria de Dados - EDA)

A etapa final utiliza o Amazon Athena para consultar os dados Parquet particionados diretamente no S3, empregando SQL para extrair insights de neg√≥cio.

| Etapa | A√ß√£o |
| :--- | :--- |
| **Cria√ß√£o da Tabela Athena**| Defini√ß√£o da Tabela Externa `telegram` no Athena, mapeando o schema do Parquet e configurando o particionamento por `context_date`. |
| **Adicionando Parti√ß√µes** | Execu√ß√£o do comando `MSCK REPAIR TABLE telegram;` para que o Athena reconhe√ßa as parti√ß√µes de dados criadas pelo Lambda no S3. |

## üìä An√°lises de Exemplo (Insights)

A otimiza√ß√£o dos dados para o Athena permite a execu√ß√£o de consultas complexas de forma eficiente:

#### Volume de Mensagens Di√°rio:

```sql
SELECT 
    context_date,
    COUNT(message_id) AS message_amount
FROM telegram
GROUP BY 1
ORDER BY 1 DESC;
```

#### M√©dia do Tamanho das Mensagens por Usu√°rio:

```sql
SELECT
    context_date,
    user_first_name,
    CAST(AVG(CHAR_LENGTH(message_text)) AS INT) AS avg_message_length
FROM telegram
WHERE context_date = '2025-10-29'
GROUP BY 1, 2
ORDER BY 3 DESC;
```

#### Frequ√™ncia de Mensagens por Hora/Semana (Engajamento):

```sql
SELECT
    CAST(EXTRACT(HOUR FROM message_date) AS VARCHAR) AS message_hour,
    DAY_OF_WEEK(message_date) AS day_of_week,
    WEEK(message_date) AS week_number,
    COUNT(message_id) AS message_count
FROM telegram
GROUP BY 1, 2, 3
ORDER BY 3, 2, 1;
```

# üõ†Ô∏è Tecnologias Utilizadas

| Categoria| Tecnologia| Uso Principal
| :--- | :--- | :--- |
| Fonte de Dados| Telegram Bot API| Ingest√£o de mensagens via Webhook.
| Orquestra√ß√£o/Processamento| AWS Lambda (Python)| Fun√ß√µes Raw (Ingest√£o) e Enriched (ETL).
| Gateway/Endpoint| AWS API Gateway| Exposi√ß√£o do endpoint HTTP para o Webhook do Telegram.
| Armazenamento| AWS S3| Data Lake (armazenamento de dados Raw e Enriched).
| Agendamento| Amazon EventBridge| Configura√ß√£o do scheduler (cron) para execu√ß√£o di√°ria do ETL.
| An√°lise/Consulta| Amazon Athena| Query engine para an√°lise explorat√≥ria dos dados Parquet.
| Bibliotecas| "boto3 pyarrow pandas"| Intera√ß√£o com servi√ßos AWS e manipula√ß√£o/escrita do formato Parquet.
